

\chapter{Differentialrechnung}\label{chap:diff}

Es gibt sehr viele -- in erster Linie mathematische -- Gründe, warum die Steigung einer Funktion eine interessante und wissenswerte Information darstellt. Doch sehen wir uns zuerst eine Situation an, die in unserem täglichen Leben vorkommt.

Der Tacho eines Autos ist etwas, dem wir ständig begegnen. Sei es als Autofahrer oder als Beifahrer, oder gar als Fahrradfahrer. Der Tacho ist ein Messinstrument und gibt die aktuelle Geschwindigkeit des Fahrzeugs an. Geschwindigkeit ist ein physikalischer Begriff. Physiker verwenden Mathematik zur Beschreibung ihrer Beobachtungen und zur Entwicklung ihrer Theorien. Sie haben zum Beispiel herausgefunden, dass wenn man den Weg, den ein Fahrzeug zurücklegt, durch die Zeit teilt, die es dafür brauchte, erhält man ein Maß für die Geschwindigkeit, bzw. ein Maß für die Änderung der zurückgelegten Strecke. Diese recht grobe Angabe stellt nur die Durchschnittsgeschwindigkeit dar. Aber man ist natürlich auch an der Geschwindigkeit interessiert, die das Fahrzeug zu jedem Zeitpunkt inne hat. Teilen wir die Strecke in $n$ gleich große Teile und messen die Zeit, die das Fahrzeug für jeden einzelnen dieser Abschnitte brauchte. Dann bekommen wir die Durchschnittsgeschwindigkeit auf jedem dieser Bereiche. Machen wir nun die Bereiche, und damit auch die Zeitabschnitte, immer kleiner ($n \rightarrow \infty$), dann nähert sich der Wert, den wir in den einzelnen Bereichen messen, immer mehr der zu diesem Zeitpunkt gefahrenen Geschwindigkeit. 

Daraus folgt ein uns völlig bekannter Zusammenhang: Nämlich, dass der Fahrer über die Geschwindigkeit, direkte Kontrolle über die zurückgelegten Strecke besitzt. Fährt er schneller, so legt er in gleicher Zeit mehr Strecke zurück. 

Eine ähnlich bekannte Situation betrifft die Beschleunigung. Werden wir in die Sitze des Autos gedrückt, so gibt der Fahrer Gas und das Fahrzeug fährt schneller. Werden wir in den Gurt gedrückt, bremst der Fahrer und das Fahrzeug wird langsamer. Die Beschleunigung ist also ein Maß für die Änderung der Geschwindigkeit. Und zwar in genau der selben Art, wie die Geschwindigkeit ein Maß für die Änderung der zurückgelegten Strecke ist:

\begin{fancyquotes}
Die Beschleunigung verhält sich zur Geschwindigkeit, wie die Geschwindigkeit zur zurückgelegten Strecke. 
\end{fancyquotes}

\section{Definitionen}

\subsection{Dehnungsbeschränktheit}\index{Dehnungsbeschränktheit}

\begin{definition}\label{def:lipschitz}
Eine Funktion $f : A \subseteq \mathbb{R} \longrightarrow \mathbb{R}$ heißt \emph{dehnungsbeschränkt}, wenn es zu beliebigen Werten $x,y\in A$ eine Konstante $K$ gibt, so dass
\[
\left\vert f(x)-f(y)  \right\vert \le K\cdot \vert x-y \vert
\]
oder auch in dieser Form dargestellt:
\[
\left\vert \frac{f(x)-f(y)}{x-y}  \right\vert \le K
\]
Diese Definition ist auch als \emph{Lipschitz-Stetigkeit}\footnote{benannt nach \textbf{Rudolf Otto Sigismund Lipschitz}, *14. Mai 1832 in Königsberg i. Pr.; \ding{61}7. Oktober 1903 in Bonn.} bekannt.\index{Lipschitz-Stetigkeit}
\end{definition}


\section{Linearisierung}\index{Linearisierung}

Unser Begriff von der Steigung ist direkt an das Verständnis gebunden, dass die Steigung einer Funktion an einem gewissen Punkt direkte Information darüber gibt, wie sich die Funktion in der Nähe dieses Punktes verhält. Der Fehler zwischen der Funktion und einer linearen Annäherung sollte also durch den Abstand zum Punkt, an dem wir die Steigung kennen, kontrollierbar sein. Wir definieren eine lineare Funktion, die im Punkt $a$ den Funktionswert von $f$  und eine Steigung $s$ besitzt über
\[
l(x) = s\cdot (x-a)+f(a)
\]
Dabei gehen wir davon aus, dass diese Annäherung nur "`in der Nähe"' von $a$ überhaupt sinnvoll ist. Daher setzen wir nun voraus, dass "`in der Nähe"' folgendes bedeutet: $|x-a|<1$.

Wir nehmen an, dass $s$ ein "`Kandidat"' für die Ableitung ist. Wir versuchen also $s$ möglichst gut zu wählen. 
Der Abstand von $f$ zu $l$ ist:
\begin{equation}\label{eq:lin}
\begin{split}
|f(x)-l(x)| &= |f(x)-(s(x-a)+f(a))| \\
&= |f(x)-f(a) -s\cdot (x-a)| \\
&\le |f(x)-f(a)| + |s||x-a| \quad \text{mit der Dreiecksungleichung} \\
&\le K\cdot |x-a| + |s||x-a| \quad \text{mit der Lipschitz-Stetigkeit von }f \\
&= \underbrace{(K+|s|)}_{=K_1}\cdot |x-a| \\
&= K_1\cdot |x-a|
\end{split}
\end{equation}

Das ist schon ein recht gutes Ergebnis. Es besagt, dass die Funktion $f$ und die \textbf{lineare} Funktion $l$ sich nicht weiter von einander entfernen, als ein Vielfaches des Abstandes von $|x-a|$. Und das haben wir ohne ernsthaften Aufwand unter Ausnutzung der Lipschitz-Stetigkeit und Einsatz der Dreiecks-Ungleichung erfahren. Auf der anderen Seite besagt Ungleichung (\ref{eq:lin}) aber auch das Folgende, wenn man in Zeile zwei $|x-a|$ ausklammert und auf beiden Seiten kürzt, dann erhält man
\begin{equation}\label{eq:const}
\left| \frac{f(x)-f(a)}{x-a} -s \right| \le K_1
\end{equation}
Da die Steigung $s$ an der Stelle $a$ unser Kandidat für die Ableitung ist, hätten wir das Problem, dass wir nicht garantieren könnten, dass die Sehne sich je an die Steigung annähert, denn mit dieser Abschätzung können wir nur sagen, dass der Abstand kleiner als eine Konstante sein muss. Sich also gegebenenfalls überhaupt nicht annähert.

\subsection{Differenzenquotient und Sehne}

Betrachten wir die Sehne von $f$\index{Sehne}
\begin{equation*}
S_f(x,a) = \frac{f(x)-f(a)}{x-a}
\end{equation*}

Es ist nicht verwunderlich, dass wir uns für den Grenzwert $\lim\limits_{x\rightarrow a} S_f(x,a)$ interessieren. Denn dieser sollte die Steigung im Punkt $a$ sein und damit die beste Wahl für die Ableitung von $f$ in $a$. Damit der Grenzwert existiert, brauchen wir an dieser Stelle die Vollständigkeit nach Definition \ref{def:voll}. Nennen wir 
\begin{equation}\label{eq:slim}
\lim\limits_{x\rightarrow a} S_f(x,a) = S_f
\end{equation}
wenn wir fordern, dass $f$ $\epsilon$-$\delta$-stetig ist, liefert uns das Lemma \ref{lem:stetig}: 
\[
|S_f(x,a) - S_f| \le C\cdot |x-a|
\]
Das sollte uns nicht überraschen, wir verschärfen damit nur (\ref{eq:const}) und setzen um, dass $|S_f(x,a) - S_f| \rightarrow 0$ für $x\rightarrow a$, was ja durch (\ref{eq:slim}) schon dargelegt wurde.
Dann folgt aus (\ref{eq:lin})
\begin{equation}
\begin{split}
|f(x)-l(x)| &= |f(x)-(S_f(x-a)+f(a))| \\
&= |f(x)-f(a) -S_f\cdot (x-a)| \\
&= \left| \frac{f(x)-f(a)}{x-a} -S_f \right| \cdot |x-a| \\
&= \left| S_f(x,a) -S_f \right| \cdot |x-a| \\
&\le C\cdot |x-a| \cdot |x-a| \\
&= C\cdot |x-a|^2
\end{split}
\end{equation}

Wiederholen wir kurz unsere Erkenntnis: Wir haben versucht, den Abstand zwischen einer Funktion $f$ und einer linearen Funktion $l$ abzuschätzen. Hierfür haben wir im Wesentlichen die Lipschitzstetigkeit von $f$ aufgenutzt. Wählen wir für die Steigung der linearen Funktion $l$ den Grenzwert der Sehnensteigung $S_f$, so bekommen wir die folgende Abschätzung -- die aufgrund des quadratischen Terms auf der rechten Seite besonders gut ist:

\begin{equation}
\left| f(x)-l(x) \right| \le C\cdot |x-a|^2
\end{equation}

Dies sollte uns darin bestärken, dass $f'=S_f$ an der Stelle $a$ eine sehr gute Wahl für die Ableitung ist und definieren wie folgt:

\begin{definition}\label{def:diff}
Wir nennen den Grenzwert der Sehnen $S_f$ die \emph{Ableitung} von $f$ am Punkt $a$ und schreiben diesen als $f'(a)$. Der Sehengrenzwert wird auch als \emph{Tangente} bezeichnet. \index{Ableitung}\index{Tangente}
\end{definition}

\bigskip

Durch die Überlegung, dass die Sehnensteigung von $f$ sich unserem Kandidaten für die Ableitung annähern soll, wenn $x$ sich immer weiter an $a$ annähert, gibt uns Lemma \ref{lem:stetig} die Ungleichung
\[
\left| \frac{f(x)-f(a)}{x-a} - f'(a) \right| \le C \cdot |x-a|
\]
Dabei implizieren wir, dass die Annäherung $x\rightarrow a$ mittels einer Folge erreicht wird. Durch Multiplikation von $|x-a|$ auf beiden Seiten erhalten wir:
\[
|f(x)-f(a) -f'(a)\cdot (x-a)| \le C\cdot |x-a|^2
\]
Im Vergleich zu (\ref{eq:lin}) ist dies eine substantielle Verbesserung, denn für $|x-a|<1$ ist $|x-a|^2\ll 1$. Das bedeutet, dass in einer kleinen Umgebung von $a$ der Abstand zwischen der Funktion $f(x)$ und der linearen Annäherung $f'(a)\cdot (x-a)+f(a)$ sehr klein ist.

Nachdem wir auf diese umständliche Art eine Begründung für die Definition \ref{def:diff} formulierten, müssen wir nun noch nachweisen, dass diese auch eindeutig ist. 

\begin{lemma}
Die Ableitung einer Funktion $f$ an der Stelle $a$ ist eindeutig. 
\end{lemma}
\begin{proof}
Es sei vorausgesetzt, dass $s_1$ und $s_2$ verschiedene Steigungen von $f$ im Punkt $a$ sind. So würde in einer kleinen Umgebung von $a$ gelten:
\begin{equation*}
\begin{split}
|f(x)-f(a) -s_1\cdot (x-a)| &\le C_1\cdot |x-a|^2 \\
|f(x)-f(a) -s_2\cdot (x-a)| &\le C_2\cdot |x-a|^2
\end{split}
\end{equation*}
Wir subtrahieren diese Ungleichungen voneinander
\begin{equation}
\begin{split}
|f(x)-f(a) -s_1\cdot (x-a)|-|f(x)-f(a) -s_2\cdot (x-a)| &\le C_1\cdot |x-a|^2-C_2\cdot |x-a|^2 \\
|f(x)-f(a) -s_1\cdot (x-a)-f(x)-f(a) -s_2\cdot (x-a)| &\le (C_1+C_2)\cdot |x-a|^2 \\
|(s_1+s_2)\cdot (x-a)| &\le (C_1+C_2)\cdot |x-a|^2 \\
|s_1+s_2| &\le (C_1+C_2)\cdot |x-a|
\end{split}
\end{equation}
(Da $C_1,C_2 >0$, ist $C_1-C_2$ immer kleiner als $C_1+C_2$). Die rechte Seite wird in der Nähe von $a$ so klein, wie wir nur wollen, während die linke Seite der Ungleichung einen konstanten Wert besitzt. Daher ist die Ungleichung falsch, sobald 
\[
|x-a| < \left| \frac{s_1+s_2}{C_1+C_2} \right|
\]
was im Widerspruch zur Voraussetzung steht, dass $s_1\ne s_2$, daher müssen diese gleich sein.
\end{proof}

\section{Rechenregeln}

Die Ableitung von verknüpften Funktionen\footnote{"`vernünftige Funktionen"' ist ein anderer Begriff für differenzierbaren Funktionen.} unterliegt Rechenregeln, die wir hier herleiten wollen. In den Aufgaben werden die einfachen Regeln für die Addition nachgewiesen. Wir konzentrieren uns hier auf die komplizierteren Fälle der Multiplikation, Division von differenzierbaren Funktionen und die Kettenregel. Im Folgenden seien $f$ und $g$ differenzierbare Funktionen sowie $x\in \mathbb{R}$.
\index{Ableitungsregeln}

\paragraph{Ableitung von Summen}
\begin{equation}\label{eq:diff0}
\left(f(x)+g(x) \right)' = f'(x)+ g'(x)
\end{equation}
Wird in den Aufgaben nachgewiesen.

\paragraph{Ableitung einer Skalaren Multiplikation}
Für $c\in \mathbb{R}$ gilt
\begin{equation}\label{eq:diff1}
\left(c\cdot f(x)\right)' = c \cdot f'(x)
\end{equation}
Wird in den Aufgaben nachgewiesen.

\paragraph{Ableitung des Produktes differenzierbarer Funktionen}
\begin{equation}
\begin{split}\label{eq:diff2}
\left(f(x) \cdot g(x) \right)' &= \lim\limits_{h\rightarrow 0} \frac{f(x+h)\cdot g(x+h)-f(x)\cdot g(x)}{h} \\
\intertext{Wir addieren eine Null}
&= \lim\limits_{h\rightarrow 0} \frac{f(x+h)\cdot g(x+h) -f(x+h)\cdot g(x)+f(x+h)\cdot g(x) - f(x)\cdot g(x)}{h} \\
&= \underbrace{\left( \lim\limits_{h\rightarrow 0}f(x+h)\right)}_{=f(x)} \cdot 
\underbrace{\lim\limits_{h\rightarrow 0} \frac{g(x+h)-g(x)}{h}}_{=g'(x)} +\underbrace{\lim\limits_{h\rightarrow 0} \frac{f(x+h)-f(x)}{h}}_{=f'(x)} \cdot g(x)\\
&= f(x)\cdot g'(x) + f'(x)\cdot g(x)
\end{split}
\end{equation}

\noindent Die Null wird in der Form
\begin{equation*}
0 = -f(x+h)\cdot g(x)+f(x+h)\cdot g(x)
\end{equation*}
im Zähler des Differentialquotient hinzugefügt.

\begin{definition}\index{Produktregel}
Die Ableitungsregel zum Produkt von Funktionen wird \emph{Produktregel} genannt.
\end{definition}

\paragraph{Ableitung des Quotienten differenzierbarer Funktionen}

Wir definieren uns eine Hilfsfunktion 
\begin{equation*}
p(x) = \frac{f(x)}{g(x)}
\end{equation*}
Damit ist 
\begin{equation*}
f(x) = p(x) \cdot g(x)
\end{equation*}
und aus der Multiplikationsregel folgt
\begin{equation*}
f'(x) = p'(x)\cdot g(x)+p(x)\cdot g'(x)
\end{equation*}
Weiter ist
\begin{equation}\label{eq:diff3}
\begin{split}
\left( \frac{f(x)}{g(x)} \right)' &= p'(x) = \frac{f'(x)-p(x)\cdot g'(x)}{g(x)} \\
&= \frac{f'(x)-\frac{f(x)}{g(x)}\cdot g'(x)}{g(x)} \\
&= \frac{f'(x)\cdot g(x)-f(x)\cdot g'(x)}{g(x)^2}
\end{split}
\end{equation}

\begin{definition}\index{Quotientenregel}
Die Ableitungsregel zur Division von Funktionen wird \emph{Quotientenregel} genannt.
\end{definition}

\paragraph{Ableitung von verschachtelten Funktionen}
Erneut definieren wir uns die Hilfsfunktion
\begin{equation*}
p(x) = f(g(x))
\end{equation*}
\begin{equation}
\begin{split}
p'(x) &= \Big(f\big( g(x) \big)\Big)' = \lim_{h\rightarrow 0} \frac{f(g(x+h))-f(g(x))}{h}\\
&= \lim_{h\rightarrow 0} \frac{f(g(x+h))-f(g(x))}{h} \cdot \frac{g(x+h)-g(x)}{g(x+h)-g(x)} \\
&= \lim_{h\rightarrow 0} \frac{f(g(x+h))-f(g(x))}{g(x+h)-g(x)} \cdot \frac{g(x+h)-g(x)}{h} \\
&= \lim_{h\rightarrow 0} \frac{f(g(x+h))-f(g(x))}{g(x+h)-g(x)} \cdot \underbrace{\lim_{h\rightarrow 0} \frac{g(x+h)-g(x)}{h}}_{=g'(x)} \\
&= \lim_{h\rightarrow 0} \frac{f(g(x+h))-f(g(x))}{g(x+h)-g(x)} \cdot g'(x)
\end{split}
\end{equation}
Hier wird zum Differentialquotient eine 1 multipliziert. Sie besteht aus dem Quotienten
\begin{equation*}
1=\frac{g(x+h)-g(x)}{g(x+h)-g(x)}
\end{equation*}
Der Trick ist in beiden Fällen der selbe: Wir fügen eine Invariante unter der Operation hinzu, die 0 bei der Addition, die 1 bei der Multiplikation.

Da $g$ eine stetige Funktion ist, geht
\begin{equation*}
g(x+h)-g(x) \longrightarrow 0,\text{ falls } h\rightarrow 0
\end{equation*}
Es sei 
\begin{equation}
i = g(x+h)-g(x), \text{ dann ist auch } g(x+h) = g(x)+i
\end{equation}
damit ist
\begin{equation}
\lim_{h\rightarrow 0} \frac{f(g(x+h))-f(g(x))}{g(x+h)-g(x)} \cdot g'(x) = 
\underbrace{\lim_{i\rightarrow 0} \frac{f(g(x)+i)-f(g(x))}{i}}_{=f'(g(x))} \cdot g'(x)
\end{equation}
und schließlich
\begin{equation}
\Big(f\big( g(x) \big)\Big)' = f'\big( g(x)\big)\cdot g'(x)
\end{equation}
\begin{definition}
Die Ableitung von ineinander verschachtelten Funktionen wird \emph{Kettenregel} genannt.
\end{definition}

\section{Ableitungen einfacher Funktionen}

Hier sollen noch die Ableitungen "`einfacher"' Funktionen (ohne näher zu spezifizieren, was "`einfache"' Funktionen sind)  dargestellt werden. Der Begriff "`einfach"' soll suggerieren, dass die Werte, wie auch die Ableitung dieser Funktionen, leicht zu berechnen sind.

\subsection{Monome und Polynome}

Beginnen wir mit einem Monom. Dieses hat einen konstanten Faktor, welcher nach Formel (\ref{eq:diff1}) bei der Ableitung ignoriert werden kann. Bleibt zu zeigen, was unter der Ableitung mit dem Rest des Monoms geschieht. 

\begin{equation}
\begin{split}
(x^n)' &= \lim_{h\rightarrow 0} \frac{(x+h)^n - x^n}{h} \\
&= \lim_{h\rightarrow 0} \dfrac{\sum_{i=0}^{n}\binom{n}{i} x^i \cdot h^{n-i} - x^n}{h}\\
&= \lim_{h\rightarrow 0} \dfrac{\sum_{i=0}^{n-1}\binom{n}{i} x^i \cdot h^{n-i}}{h}\\
&= n\cdot x^{n-1} + \lim_{h\rightarrow 0} \dfrac{\sum_{i=0}^{n-2}\binom{n}{i} x^i \cdot h^{n-i}}{h} \text{, kürze um ein $h$} \\
&= n\cdot x^{n-1} + \underbrace{\lim_{h\rightarrow 0} \sum_{i=0}^{n-2}\binom{n}{i} x^i \cdot h^{n-i-1}}_{\rightarrow 0}\\
&= n\cdot x^{n-1}
\end{split}
\end{equation}

\noindent Zur Erklärung:

\begin{enumerate}
\item In Zeile zwei haben wir die allgemeine Binomische Formel (\ref{eq:allgbinom}) verwendet, um die Klammer $(x+h)^n$ aufzulösen.
\item In Zeile drei splitten wir die Summe in den höchsten Term $x^n$ und den Rest und subtrahieren davon $x^n$. Damit bleibt die Summe nur bis $n-1$ erhalten. Das funktioniert, weil $\binom{n}{n}=1$ ist, sowie $h^{n-i}=1$ bei $i=n$ ist. Also ist der letzte Summand (wenn $i=n$ ist) $=x^n$.
\item In Zeile vier nehmen wir wiederum den höchsten Term der Summe und splitten so $\frac{n\cdot x^{n-1}\cdot h}{h}$ ab und kürzen um $h$. Da dies dann von $h$ unabhängig ist, kann dieser Teil aus der Grenzwertbetrachtung herausgenommen werden.
\item In Zeile 5 haben wir alle Summanden des Zählers um ein $h$ gekürzt. Dies können wir tun, da der Summand mit dem kleinsten $h$-Faktor der folgende ist: $h^{n-i-1}$ bei $i=n-2$ maximal, sodass $h^{n-(n-2)-1}=h^{n-n+2-1}=h$ ist.
\item Und schließlich folgern wir, dass alle Summanden, die mit einem Faktor $h$ versehen sind, zwangsläufig gegen 0 streben, wenn $h\rightarrow 0$ geht. 
\end{enumerate}

\noindent Das bedeutet, die Ableitung eines vollständigen Monoms ist wie folgt:
\begin{equation}
\left( a\cdot x^n \right)' = a\cdot n\cdot x^{n-1}
\end{equation}


Zusammen mit den Formeln (\ref{eq:diff0}) und (\ref{eq:diff1}) ergibt sich für Polynome ($p_n$ ist wie in Formel (\ref{eq:polynom}) definiert):

\begin{equation}
\begin{split}
\big( p_n(x) \big)' &= \left( \sum_{i=0}^{n} a_i \cdot x^i \right)' \\
&= \sum_{i=1}^{n} i\cdot a_i \cdot x^{i-1}
\end{split}
\end{equation}

Zu beachten ist, dass die Summer bei $i=1$ und nicht bei $i=0$ beginnt. Das liegt daran, dass konstante Funktionen keine Steigung besitzen (halt eben weil sie konstant sind). Daher ist ihre Ableitung 0 und sie fallen aus der Formel heraus. Die nächste Ableitung würde bei $i=2$ beginnen, und so weiter. Man kann also Polynome immer weiter ableiten, bis nach der n-ten Ableitung nur noch ein Konstanter Wert übrig bleibt:
\begin{equation*}
\big( p_n(x)\big)^{(n)} = 1\cdot 2 \cdot \dots \cdot n \cdot a_n
\end{equation*}
(Das $(n)$ im Exponent bedeutet, dass wir die $n$-te Ableitung bestimmen wollen). Auch diese konstante Funktion kann man wiederum ableiten und es gilt 
\begin{equation*}
p_n(x)^{(m)} = 0 \text{ für } m>n
\end{equation*}
für alle Polynome.

\subsection{Logarithmus}

\subsection{Exponentialfunktion}




