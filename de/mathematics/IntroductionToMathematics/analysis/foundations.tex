
\chapter{Grundlagen}

Die Analysis, auch Infinitesimalrechnung genannt, wurde von Gottfried Wilhelm Leibnitz\footnote{\textbf{Gottfried Wilhelm Leibnitz}, *1. Juli 1646 in Leibzig; \ding{61}14. November 1716 in Hannover} und Isaac Newton\footnote{\textbf{Sir Isaac Newton}, *4. Januar 1643 in Woolsthorpe-by-Colsterworth in Lincolnshire; \ding{61}31. März 1727 in Kensington} unabhängig voneinander entwickelt. Sie behandelt Grenzwerte von Folgen und Reihen, Funktionen reeller Zahlen, deren Stetigkeit, Differenzierbarkeit und Integrierbarkeit. 

\section{$\epsilon$-$\delta$-Kriterien}

Im Folgenden werden wir mehrfach Definitionen kennen lernen, die einem Dreifachschritt aus Rahmenbedingung, Anforderung und Folgerung bestehen. Aufgrund der darin auftauchenden Zahlen $\epsilon\in \mathbb{R}$ und $\delta\in\mathbb{R}$ werden diese Kriterien allgemein als $\epsilon$-$\delta$-Kriterien bezeichnet (manchmal auch \emph{Epsilontik}). Grundsätzlich unterscheiden sich natürlich alle diese Definitionen voneinander, da sie in völlig verschiedenen Zusammenhängen stehen. Gemeinsam haben sie, dass die Definitionen in der folgenden Form vorgebracht werden:

\begin{enumerate}
\item Zu jedem $\epsilon>0$ gibt es ein $\delta>0$, sodass aus
\item $\text{Definitionsbereich} < \delta$,
\item $\text{Funktionsbereich} < \epsilon$ folgt.
\end{enumerate}

So unscheinbar dieser Dreierschritt auch ist, so wird er uns immer wieder in der Analysis begegnen. So ist die Konvergenz von Folgen, die Differenzierbarkeit und die Integrierbarkeit durch ein solches Konstrukt definiert. Aufgrund der Wichtigkeit sollten wir uns diese Vorgehensweise hier etwas näher ansehen.

TODO


\section{Folgen}

Folgen sind ein zentraler Begriff in der Mathematik, im Besonderen der Analysis. Die Betrachtung von Folgen und ihrem Verhalten, hat viele Bereiche der Mathematik inspiriert, so wäre die Funktionentheorie ohne die Banach\footnote{\textbf{Stefan Banach}, polnischer Mathematiker,  *30. März 1892 in Krakau, \ding{61}31. August 1945 in Lemberg}-Räume kaum vorstellbar. \index{Banach Raum}\index{Banach, Stefan} Banachräume sind bestimmte Vektorräume, in denen jede Cauchy-Folge gegen einen im Raum enthaltenen Wert konvergiert.

\begin{definition}
Eine \emph{Folge} ist eine -- wie der Name suggeriert -- Abfolge von Mathematischen Objekten. Dies können zum Beispiel Zahlen, Vektoren oder Funktionen sein, oder jedes andere Mathematische Objekt, solange sich diese in eine Reihenfolge bringen lassen. Bei Folgen ist eine Reihenfolge der Elemente festgelegt. Sind $a_i$ die Elemente einer Folge, so ist immer $a_{i-1}$ vor $a_i$ und diesem folgt immer $a_{i+1}$ -- sofern $a_{i\pm 1}$ existieren. Eine Folge wird in dieser Art dargestellt:
\[
(a_1, a_2, \dots)
\]
\end{definition}

Folgen sind keine Mengen, in Folgen können Elemente mehrfach vorkommen, an unterschiedlichen Positionen in der Abfolge der Elemente! Des Weiteren sind die Elemente von Folgen nicht notwendigerweise sortiert. Es gibt monoton steigende oder fallende Folgen. In diesen gelten Vergleichsoperationen. Aber allgemein ist dies nicht von den Elementen einer Folge zu erwarten und es sollte auch nicht davon ausgegangen werden. Das einzig entscheidende Ordnungskriterium ist der Index. Ist $i<j$, dann ist immer $a_i$ in der Folge \textbf{vor} $a_j$.

Es gibt endliche Folgen, doch uns interessieren hier nur Folgen mit unendlich vielen Elementen. Diese sind mit den natürlichen Zahlen abzählbar unendlich (siehe Definition \ref{abzaehlbar}).

\subsection{Charakterisierung}

\begin{definition}
Eine Folge heißt \emph{monoton steigend}\index{monoton steigend}, wenn für alle $i\in \mathbb{N}$ gilt $a_i\le a_{i+1}$. Sie heißt \emph{streng monoton steigend}, wenn $a_i < a_{i+1}$ gilt. Äquivalent heißt sie \emph{monoton fallend}\index{monoton fallend}, wenn $a_i\ge a_{i+1}$ gilt, bzw. \emph{streng monoton fallend}, wenn $a_i > a_{i+1}$ gilt.
\end{definition}

Monotonie\index{Monotonie} kann auch erst ab einem gewissen $n\in \mathbb{N}, n>1$ nachweisbar sein. Die Folge wird dann als monoton ab dem Folgenglied $n$ bezeichnet.

\begin{definition}
Eine reelle Folge ($a_i \in \mathbb{R}$) heißt \emph{beschränkt}, wenn es ein $S\in \mathbb{R}$ gibt, sodass für alle $i\in \mathbb{N}$, $a_i \le S$ gilt. $S$ ist eine \emph{obere Schranke}\index{Schranke, obere} der Folge. Gibt es eine kleinste obere Schranke $S'$, so wird diese \emph{Supremum}\index{Supremum} genannt. 

Gibt es ein $I\in \mathbb{R}$ mit $a_i \ge I$, so wird $I$ \emph{untere Schranke}\index{Schranke, untere} genannt. Die größte untere Schranke wird \emph{Infimum}\index{Infimum} genannt.
\end{definition}

\begin{definition}
Eine Folge, deren Elemente alle identisch sind, wird \emph{konstante Folge}\index{konstante Folge} genannt. Eine Folge, deren Elemente abwechselnd positiv und negativ sind, wird \emph{alternierend}\index{alternierend} genannt. Eine Folge deren Elemente sich immer weiter der 0 annähern, wird \emph{Null-Folge}\index{Null-Folge} genannt.
\end{definition}

\subsection{Konvergenz}

\begin{definition}\label{def:lim}
Es sei $(a_i)$ eine Folge in den reellen Zahlen und $a\in \mathbb{R}$ eine Zahl. Weiterhin sei $\epsilon>0$ eine beliebige reelle Zahl. Wenn es für jeden solchen Wert $\epsilon$ einen Folgenindex $n_\epsilon \in \mathbb{N}$ gibt, sodass $\vert a_i -a\vert <\epsilon$ für alle $i\ge n_\epsilon$ gilt, so heißt die Folge \emph{kovergent}\index{konvergent}. Ist die Folge konvergent gegen $a$, so nennt man $a$ den \emph{Grenzwert}\index{Grenzwert} der Folge $a_i$.
\end{definition}

Man sollte sich das $\epsilon$ als eine sehr kleine Zahl vorstellen. Für große Zahlen sind die Bedingungen der Konvergenz recht einfach zu erfüllen. Schwierig wird es erst, wenn $\epsilon\ll 1$ ist. ($\ll$ bedeutet "`wesentlich kleiner als"').

Die oben dargestellte Definition für Konvergenz beruht darauf, dass der Punkt $a$ bereits bekannt ist. Was ist aber, wenn wir $a$ nicht kennen? Gibt es dann auch ein Kriterium für die Konvergenz?

\begin{definition}
Es sei $(a_i)$ eine Folge. Es sei $\epsilon \ll 1$. Wenn es zu jedem $\epsilon$ ein $N_\epsilon \in \mathbb{N}$ gibt, sodass für $n,m > N_\epsilon $ gilt $\vert a_n -a_m \vert <\epsilon$, so ist auch diese Folge konvergent. Bemerkenswert dabei ist, dass wir nur die Abstände der Folgenelemente dafür betrachten und keinen Grenzwert. Eine solche Folge wird \emph{Cauchy-Folge}\footnote{benannt nach dem französischen Mathematiker \textbf{Augustin-Louis Cauchy}, *21. August 1789, \ding{61}23. Mai 1857 in Sceaux}\index{Cauchy-Folge} genannt.
\end{definition}

Cauchy-Folgen haben die positive Eigenschaft, dass man ihre Konvergenz nachweisen kann, ohne den Grenzwert zu kennen. Z.B. in den rationalen Zahlen $\mathbb{Q}$ gibt es Cauchy-Folgen, die keinen Grenzwert besitzen, weil dieser in den irrationalen Zahlen liegt.


\begin{definition}
Zu einer Folge $a_i$ heißt die Menge $\lbrace a_i \rbrace$ die \emph{Menge der Folgenwerte}. Es wird der Einfachheit halber eine Folge auch oft mit der Menge ihrer Folgenwerte gleichgesetzt. Dies ist aber nicht vollständig korrekt, da eine Folge auch Informationen über die Reihenfolge ihrer Elemente enthält, die Menge der Folgenwerte aber nicht. 
\end{definition}

\section{Grenzwert}

In Definition \ref{def:lim} wurde bereits der Begriff \emph{Grenzwert} verwendet. Hier soll er noch einmal formal dargestellt werden. 

\begin{definition}
Sei $(a_i)$ eine Folge in $A\subseteq \mathbb{R}$. Wenn die Folge gegen einen Wert $a\in A$ konvergiert, so heißt $a$ \emph{Grenzwert}, oder auch \emph{Limes}\footnote{Limes lat. "`Grenzweg"'}\index{Limes}\index{lim} der Folge $(a_i)$. Dass $(a_i)$ den Grenzwert $a$ besitzt, wird wie folgt ausgedrückt:
\[
\lim_{n\rightarrow \infty} a_n = a
\]
\end{definition}

\begin{definition}\label{def:voll}
Wenn jede Cauchy-Folge mit $(a_n)\in A\subseteq \mathbb{R}$ konvergiert und ihr Grenzwert 
\[\lim_{n\rightarrow \infty} a_n = a\in A\] 
existiert, so heißt $A$ \emph{vollständig}\index{vollständig}. 

Die Vollständigkeit der reellen Zahlen in der Form, dass alle Cauchy-Folgen konvergieren und ihren Grenzwert annehmen, ist eine Konsequenz aus dem sogenannten \emph{Vollständigkeitsaxiom}\index{Vollständigkeitsaxiom}. Die Vollständigkeit folgert also nicht aus der Konvergenz der Cauchy-Folgen, sondern genau umgekehrt folgert die Konvergenz der Cauchy-Folgen aus der Vollständigkeit. 
\end{definition}


Der Begriff \emph{Axiom}\index{Axiom} bezeichnet einen Satz oder eine Voraussetzung innerhalb einer Theorie, der/die beweislos als richtig angesehen wird. Er leitet sich vom griechischen "`\begin{greek}'axi'wmata\end{greek}"' -- "`axi\'omata"' her: Würdiger, anerkannter Satz.

\bigskip 

Grenzwertbetrachtungen sind nicht nur für Folgen interessant. Im späteren werden wir bei der Differentialrechnung intensiven Gebrauch von Grenzwerten machen. Dort betrachten wir Brüche, deren Zähler und Nenner gegen Null streben. Wie wir früher gesehen haben, sind Brüche, deren Zähler 0 ist, gleich 0 während Brüche, deren Nenner 0 ist, als undefiniert gelten. Mit den Grenzwertbetrachtungen kann man aber das Verhalten der Brüche analysieren und kontrollieren, sodass ein endlicher Wert dabei herauskommt. Wir betrachten dann Grenzwerte der Form
\begin{equation}
\lim\limits_{h \rightarrow 0} \dots
\end{equation}

Auf der anderen Seite werden wir bei der Integralrechnung Summen von immer größeren Anzahlen von immer schmäleren Streifen berechnen. Also Unendliche Summen von unendlich kleinen Dingen berechnen. Auch dort setzen wir Grenzwerte ein, die folgende Form haben:
\begin{equation}
\lim\limits_{n \rightarrow \infty} \dots
\end{equation}
Auch hier werden wir versuchen, endliche Dinge zu berechnen, nur dieses Mal aus unendlichen Summen. 

In beiden Fällen werden Grenzwerte eingesetzt, deren Art und Weise, wie gegen $0$ oder $\infty$ "`gestrebt"' wird, nicht klar gesagt wird. 

Beim Streben gegen $0$ ist dies auch nicht weiter nötig, man geht von einer beliebigen Null-Folge aus, die die Werte von $h$ bildet. 

Beim Streben gegen $\infty$ ist das etwas anderes. Man könnte ja auch mit allen Primzahlen gegen unendlich streben. Oder irgendeiner anderen, divergenten Folge. Aber meistens ist mit solchen \emph{Grenzübergängen} nach Unendlich eine Abfolge natürlicher Zahlen gemeint. Und erst, wenn etwas anderes gewollt ist, wird es zusätzlich dazugeschrieben.

\section{Reihen}

\begin{definition}
Sei $(a_i)$ eine Folge, so ist 
\[
s_n = \sum_{i=1}^{n} a_i
\]
die $n$-te \emph{Partialsumme}\index{Partialsumme}. Die Partialsummen bilden wiederum eine Folge $(s_i)$. Falls der Grenzwert 
\[
R(a) = \lim_{n\rightarrow \infty} s_n = \lim_{n\rightarrow \infty} \sum_{i=1}^{n} a_i
\]
existiert, so heißt $R(a)$ eine \emph{Reihe}\index{Reihe}.
\end{definition}

Ob eine Reihe existiert, bestimmt die Partialsummen-Folge. Konvergiert diese, so existiert der Grenzwert, und damit auch die Reihe. Aus der Definition der Partialsummen folgt, dass wenn die Partialsummen-Folge konvergiert, $(a_n)$ eine Null-Folge sein muss. Falls $(a_n)$ keine Null-Folge ist, divergieren die Partialsummen und der Grenzwert  existiert nicht. Allerdings reicht es nicht aus $(a_n)$ als Null-Folge zu wählen, es gibt Null-Folgen, deren Partialsummen trotzdem divergieren. 

Ein Beispiel für eine nicht konvergente Summe aus einer Null-Folge ist die Harmonische Reihe:
\[
H_n = \sum_{i=1}^{n} \frac{1}{i}
\]
Die Folge $\lbrace 1, \frac{1}{2}, \frac{1}{3}, \dots \rbrace$ ist eine Null-Folge, aber die $H_n$ sind divergent.

\begin{definition}
Eine Reihe heißt \emph{absolut konvergent}, wenn 
\[
R'(a) = \lim_{n\rightarrow \infty} \sum_{i=1}^{n} \vert a_i \vert
\]
konvergiert.
\end{definition}

\begin{lemma}
Falls zu jedem $\epsilon \ll 1$ ein Index $N$ existiert, sodass für alle $n>N$ gilt
\[
\left\vert \frac{a_{n+1}}{a_n} \right\vert \le \epsilon
\]
dann konvergiert die Reihe 
\[
\lim\limits_{n\rightarrow \infty} \sum_{i=1}^{n} \vert a_i \vert
\]
Sie ist also absolut konvergent. Dies wird als \emph{Quotienten-Kriterium} bezeichnet.
\end{lemma}
\begin{proof}
TODO
\end{proof}


\section{Stetigkeit}

Es sei $A\subseteq \mathbb{R}$. Wir betrachten alle Folgen $(a_i)\in A$, die einen Grenzwert $a\in A$ besitzen, sowie eine Funktion $f: A\longrightarrow \mathbb{R}$. 

\begin{definition}
Die Funktion $f$ heißt \emph{stetig}\index{stetig}, wenn für jede Folge $(a_i)$ mit Grenzwert $a$ auch die Folge $(f(a_i))$ gegen $f(a)$ konvergiert. Formal definiert
\[
\lim_{n\rightarrow \infty} f(a_n) = f(\lim_{n\rightarrow \infty} a_n) = f(a)
\]
\end{definition}

Diese Definition der Stetigkeit wird auch \emph{Folgenstetigkeit}\index{Folgenstetigkeit} genannt. Eine Definition der Stetigkeit unabhängig von Folgen ist die folgende: 

\begin{definition}
$f$ ist genau dann in $a$ \emph{stetig}, wenn es zu jedem $\epsilon>0$ ein $\delta_\epsilon > 0$ gibt, so dass für alle $b\in A$ mit $\vert b-a\vert < \delta_\epsilon $ immer $\vert f(b)-f(a)\vert < \epsilon$ ist. Diese Definition wird meist $\epsilon$-$\delta$-Stetigkeit genannt. \index{$\delta$-$\epsilon$-stetig}
\end{definition}

Wir hatten bisher versucht, mehrere Definitionen für einen Begriff zu vermeiden. Allerdings passiert es, dass die Stetigkeitseigenschaft in unterschiedlichen Zusammenhängen ausgenutzt werden muss. Daher ist es zuweilen auch notwendig, unterschiedliche Definitionen heranzuziehen, um in einem Beweis die Stetigkeit prägnant auszunutzen. Stetigkeit ist noch auf weitere Arten definierbar: Z.B. im topologischen Sinne, dass unter stetigen Abbildungen die Urbilder offener Mengen wieder offene Mengen sind. Aber das würde an dieser Stelle zu weit führen.

\begin{lemma}\label{lem:stetig}
Sei $f$ eine $\epsilon$-$\delta$-stetige Funktion und $(a_n)\in A \subseteq \mathbb{R}$ eine Folge mit dem Grenzwert $a$. Dann gilt
\[
|f(a_n)-f(a)| \le C\cdot |a_n -a|
\]
\end{lemma}
\begin{proof}
Der Beweis ist sehr einfach. Für ein beliebiges $n$ wählen wir $\epsilon = C\cdot |a_n -a|$. Dann gibt es zu diesem aufgrund der Stetigkeit immer ein $\delta_\epsilon$, sodass aus $|a_n-a|<\delta_\epsilon$ folgt:
\[
|f(a_n)-f(a)| < \epsilon = C\cdot |a_n -a|
\]
also auch
\[
|f(a_n)-f(a)| \le C\cdot |a_n -a|
\]
\end{proof}

\begin{remark}
Dies ist eine mit Folgen dargestellte Lipschitz-Stetigkeit. Siehe Definition \ref{def:lipschitz}
\end{remark}

\section{Zwischenwertsatz}

Der Zwischenwertsatz ist ein elementarer Satz der Analysis. Es besagt, dass eine stetige Funktion über einem Intervall $[a,b]$ alle Zwischenwerte annimmt.

\begin{satz}[Zwischenwertsatz]\label{satz:zwischen}
Sei $f:[a,b]\longrightarrow \mathbb{R}$ eine stetige Funktion. Dann gibt es zu jedem $Z\in[f(a),f(b)]$ ein $z\in [a,b]$ mit $f(z)=Z$.
\end{satz}
\begin{proof}
Ohne Beschränkung der Allgemeinheit sei $f(a)\le f(b)$. Wäre $f(b)>f(a)$, dann könnte der Beweis mit $Z\in[f(b),f(a)]$ genauso geführt werden. Wir setzen $g(x) = f(x)-Z$. Dann gilt $g(a)\le 0 \le g(b)$. Weiter definieren wir uns eine Folge von Intervallen:

\begin{enumerate}
\item $a_0 = a$ und $b_0 = b$, also $I_0 = [a_0,b_0]=[a,b]$.
\item Wir definieren mit $c_k = \frac{a_k +b_k}{2}$ die Mitte des $k$-ten Intervalls $I_k$.
\item Ist $g(c_k)<0$ setzen wir $I_{k+1} = [c_k,b_k]$, andern falls $I_{k+1}=[a_k,c_k]$.
\item Wäre $g(c_k)=0$, sind wir fertig und $c_k=z$.
\item Setze $k=k+1$ und gehe zu Punkt 2.
\end{enumerate}
Beachte, dass jedes Intervall $I_{k+1}$ nur noch halb so groß ist, wie $I_k$. Der Abstand zwischen $a_{k+1}$ und $b_{k+1}$ ist somit ebenfalls nur noch halb so groß wie der Abstand von $a_k$ zu $b_k$. Und für alle gilt $a_k\le b_k$. Die Folgen $a_k$ und $b_k$ haben somit einen gemeinsamen Grenzwert
\begin{equation}
\lim_{n\rightarrow \infty} g(a_k) =g(z)=\lim_{n\rightarrow \infty} g(b_k)
\end{equation}
Da $f$ stetig ist, gilt dies auch für $g$. Zusammen mit der Vollständigkeit des Intervalls $[a,b]$ folgt, dass der Grenzwert $z$ existiert und $g(z)=0$ bzw.
\begin{equation}
f(z)=Z
\end{equation}
was zu beweisen war.
\end{proof}

\begin{remark}
Beachte, dass der Zwischenwertsatz nicht die Eindeutigkeit des Zwischenwertes voraussetzt! Zwischenwerte könnenn vielfach angenommen werden. Der Zwischenwertsatz liefert nur die Existenz, aber keinesfalls die Eindeutigkeit des Zwischenwertes.
\end{remark}
